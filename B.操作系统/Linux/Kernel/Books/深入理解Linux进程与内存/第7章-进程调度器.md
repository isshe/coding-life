# 进程调度器

## 问题

- 调度器的发展过程？
  - 无论是什么调度算法，都是围绕以下两个问题：
    - CPU 如何选择下面让哪一个任务执行？
    - 允许选中的进程运行多长的时间？
- 进程不主动释放 CPU 的话，每次调度最少能运行多久？最多能运行多久？
- 现在的进程调度还是按时间片来执行的吗？
- 进程的 nice 值的含义是什么？
- 在用户进程中，高优先级是否能抢占低优先级的 CPU？
- 业界流行的在离线混部有没有副作用？
- 为什么进程会在 CPU 各个核之间飘来飘去？
- taskset 命令是如何让一个进程钉在某个核上的？
- 最新内核或 5.14 及之后的调度器是什么类型的？相关的代码或宏定义有哪些？（SCHED_RR...）
- 实时进程和普通用户进程是怎么区分的？内核是如何知道的？是内核自行识别的吗？
- CFS（完全公平调度）中，如何通过调度实体结构体（sched_entity）找到对应的进程 task_struct 的呢？
- 进程创建后，是如何加入到调度任务队列中的？
- 一个进程在某个 CPU 调度过后，还能迁移到其他 CPU 上执行吗？
- 调度时 CPU 核心选择顺序？
  - 根据缓存进行选择：同一个物理核（2 个逻辑核，L1/L2 共享）-> 同一个物理 CPU（L3 共享） -> 不同物理 CPU。
- 什么是在离线混部？
- 进程一次调度完成后，会放到哪里呢？何时再选择 CPU 进行调度呢？
- 加入到运行队列，是否就意味着调度了呢？如果不是，是如何进行调度的呢？
- 进程 nice 值？
- 进程什么时候要让出 CPU？也就是是否需要抢占当前任务？
- 什么是调度域（sched domain）？
- 什么是调度组（sched group）？
- 负载均衡的过程是怎样的？负载均衡是什么时候进行的？
- 怎样才算平衡呢？
- 调度的过程？
- 什么时候会触发调度/上下文切换？
- 保存进程上下文时，都保存到哪里？
- 任务切换都有哪些开销？
- 进程上下文包含哪些内容？

## 总结

### 调度器的发展过程？

> 无论是什么调度算法，都是围绕以下两个问题：
>   - CPU 如何选择下面让哪一个任务执行？
>   - 允许选中的进程运行多长的时间？

先进先出：任务都加入到一个队列中，先来先服务。问题：短时任务需等待长时任务完成，系统整体的响应能力非常差。
->
短作业优先：先评估处理所需的耗时，再进行处理，时间短的优先处理。问题：不公平，长作业可能一直得不到执行。
->
时间片轮转：开始考虑公平性，每个任务都指定固定的时间，时间到执行下一个任务，任务未完成就继续进入等待队列。问题：“太公平”，耗时少的紧急任务无法优先处理。
->
Linux 2.4 O(n) 调度器：同时加入动态和静态优先级，根据静态优先级和任务执行情况，计算动态优先级，避免短作业优先算法的长时任务饿死问题和时间片轮转算法中的问题。
随着 CPU 硬件在单核主频上受到物理极限限制，CPU 开始朝着多核发展，O(n) 调度器出现问题：单任务队列，锁竞争严重；O(n) 遍历方式也低效。
->
Linux 2.5 O(1) 调度器：采用多优先级（0-139 级）任务队列，同时引入 bitmap 辅助实现 O(1) 查找。
  - 优先级 0-99 给实时进程，实时进程只有静态优先级，优先级高的进程拥有绝对的优先权，并且能抢占低优先级进程的 CPU 时间。
  - 优先级 100-140 给普通进程
-> 完全公平调度器：TODO
  - 核心思想：强调让每个进程尽量公平地分配 CPU 时间。
  - 精髓：对于 N 个进程的系统，在时间周期 T 内，每个进程运行 T/N 的时间。
  - 摒弃了固定时间片的思路，根据当前系统的情况动态计算调度周期。
  - 但绝对公平是不现实的，有的进程可能确实需要更多的 CPU，所以实际上分配是按比例来的，比例是由优先级决定的。

### 进程不主动释放 CPU 的话，每次调度最少能运行多久？最多能运行多久？

Linux 内核 2.5.68 中，有以下定义：

```c
#define MIN_TIMESLICE (10 * HZ / 1000)
#define MAX_TIMESLICE (200 * HZ / 1000)
```

也就是最小时间片是 `10 * HZ / 100`，最大时间片是 `200 * HZ / 1000`。
`HZ` 代表时钟中断的次数，不是实际的时间单位，通过 `jiffies_to_time*` 相关函数转换成时间。上面两个值分别是 `10,000us(10ms)` 和 `200,000us(200ms)`。
优先级越高获得的时间片越多。


### 实时进程和普通用户进程是怎么区分的？内核是如何知道的？是内核自行识别的吗？

通过 `task_struct` 的 `policy` 字段识别。

`policy` 取值：（TODO 到内核源码中确认）

- SCHED_NORMAL：非实时，普通进程（也叫 SCHED_OTHER）
- SCHED_BATCH：非实时，批处理任务
- SCHED_IDLE：非实时，最低优先级任务（几乎闲时才运行）
- SCHED_FIFO：实时，先到先服务的实时任务
- SCHED_RR：实时，时间片轮转的实时任务
- SCHED_DEADLINE：实时，基于截止时间的实时任务（EDF）

不是内核自行识别的。是进程（程序/线程）自己主动设置或外部（系统管理员、调度器、服务管理器等）手动设置。

TODO：更多


### CFS（完全公平调度）中，如何通过调度实体结构体（sched_entity）找到对应的进程 task_struct 的呢？

通过 `task_of`。实际展开其实是用的 `container_of`。例如 `container_of(se, struct task_struct, se)`。

`container_of`：根据 sched_entity 的地址和 sched_entity 在 task_struct 中的偏移地址，计算得到 task_struct 地址。


### 进程创建后，是如何加入到调度任务队列中的？

```
- kernel_clone
  \- copy_process: 对进程进行初始化
    \- sched_fork: 调度相关的初始化
      \- _sched_fork: 初始化 task_struct.se （sched_entity），包括 vruntime 等字段都初始化为 0。
  \- wake_up_new_task: 进入到就绪队列中，等待调度器调度
    \- __set_task_cpu: 为进程选择合适的 CPU，以及指定运行队列
    \- activate_task: 将进程添加到运行队列红黑树中
```

vruntime 初始化为 0 有个问题：新进程的 vruntime 比老进程**小得多**，也就是调度优先级更高，会在比较长的时间内都占据调度优势，这不公平。
解决办法是，调度器会在每个 cfs_rq 中维护一个 min_vruntime 值，存储当前队列中所有进程的最小 vruntime。在进程真正加入运行队列时，会将 vruntime 设置为 min_vruntime。

### 进程 nice 值？

nice 取值范围是 -20（最高权重） ~ 19（最低权重）。
nice 值不是表示进程的调度优先级（也就是优先被调度），而是表示分配的占用 CPU 时间的比例。nice 值越小运行任务占用 CPU 的权重越高。这个权重是一个分配比例，而不是具体的时间。

### 进程什么时候要让出 CPU？也就是是否需要抢占当前任务？

以下两种情况需要：

- 当前仅实际运行的时间比根据调度周期算出的时间预期运行时间长了（也就是运行太久了，运行时间到了）
- 当前进程的 vruntime 已经比红黑树最左侧（vruntime 最小）的任务的 vruntime 大不少了。
  - **不少**具体是多少？sched_slice 计算出来的 ideal runtime（理想运行时间）

相关逻辑在 `check_preempt_tick` 函数中。

### 什么是调度域？

为了对应 CPU 的缓存分层结构（前面提到的 CPU 选择顺序），设计的数据结构。
调度域的层次：

```
NUMA域 (NUMA节点间)
  ↓
PKG域 (同一CPU包)
  ↓
MC域 (同一物理CPU的多核心)
  ↓
SMT域 (同一物理核心的超线程)
```

### 什么是调度组（sched group）？

调度组是调度域内部的划分单元，用于实际的负载均衡操作。
调度组示例：（4 核 8 线程）

```
NUMA域: CPU 0-7
  └── 调度组1: CPU 0-7

PKG域: CPU 0-7
  └── 调度组1: CPU 0-7

MC域: CPU 0-7
  └── 调度组1: CPU 0-3
  └── 调度组2: CPU 4-7

SMT域:
  ├── CPU 0,4 → 调度组: CPU 0,4
  ├── CPU 1,5 → 调度组: CPU 1,5
  ├── CPU 2,6 → 调度组: CPU 2,6
  └── CPU 3,7 → 调度组: CPU 3,7
```

也就是调度域比调度组更大，调度组是调度域的子集。

### 负载均衡的过程是怎样的？负载均衡是什么时候进行的？是如何进行的？

注意：负载均衡的单位是调度组，不是调度域。

在调度节拍中定时发起的；在 scheduler_tick 函数中调用 trigger_load_balance 来触发，trigger_load_balance 则通过触发一个软中断来让 ksoftirqd 现成处理真正的负载均衡过程。
软中断是 SCHED_SOFTIRQ，在系统初始化的时候就已经设置好中断处理函数 —— run_rebalance_domains（完全公平调度器的）。
负载均衡的过程是：从最底层开始遍历每一层调度域，优先尝试在最底层调度域实现负载均衡，如果无法实现，再逐级往上。（因为前面提到的缓存命中的问题）。负载均衡的过程在 rebalance_domains 中。
- 选择调度域：从最底层调度域开始
- 当前 CPU 负载检查：判断当前 CPU 是否有余力处理更多任务
- 查找最忙的调度组：在该域中找到负载最重的组
- 选择源队列：从最忙组中找到最忙的队列
- 迁移任务：将任务从源 CPU 迁移/拉取（detach_tasks）到当前 CPU

注意：并不是所有任务都能拉取，例如通过 taskset 或调用 sched_setaffinity 的则不能拉。是否能拉取通过 can_migrate_task 判断。

### 怎样才算平衡呢？

TODO

### 调度的过程？

调度 是在 schedule 函数中进行的，其中核心函数是 schedule 中调用的 __schedule 函数。

调度过程：

- 获取当前 CPU ID（smp_processor_id）
- 获取当前 CPU 的任务队列（cpu_rq）
- 从任务队列中选择一个任务（pick_next_task）
- 进行上下文切换（context_switch），将新进程切换到运行状态
  - 保存老进程上下文
  - 执行地址空间切换（switch_mm_irqs_off）
  - 执行栈和寄存器切换（switch_to）

### 什么时候会触发调度/上下文切换？

- 时间片用完
- 网络/硬盘 IO（主动让出执行权）

### 保存进程上下文时，都保存到哪里？

### 任务切换都有哪些开销？

可以分为两种开销：直接开销和间接开销。

直接开销：切换过程中，必须要做的事情，例如地址空间、栈、寄存器切换等。
简介开销：缓存还不热，刚开始运行速度较慢。

### 进程上下文包含哪些内容？

包含地址空间、栈、寄存器等。

## 草稿

CPU 调度是在**缓存性能**和**空闲核**这两个点之间做权衡。
