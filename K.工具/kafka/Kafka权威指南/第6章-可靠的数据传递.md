[TOC]

第六章 可靠的数据传递
---

# 什么是可靠性保证？
* 可靠性保证是指：确保系统在各种不同的环境下行为一致。
* ACID：原子性、一致性、隔离性、持久性。
  * 支持`事务`相关的行为。

# Kafka的可靠性保证有哪些？
* 保证分区消息的顺序。（同一分区，先生产先消费）
* 只有消息被写入分区的所有`同步副本`(不一定要写入磁盘)，才被认为是`已提交`的。
* 只要还有一个副本是活跃的，那么提交的消息就不会丢失。
* 消费者只能读取已经提交的消息。

# Kafka是如何提供可靠性保证的？
* 复制机制；
* 分区的多副本架构；

# Kafka的复制功能是如何提高系统可靠性的？


# 如何验证系统的可靠性？
* 配置验证
  * 验证配置是否满足需求；
  * 了解系统的真正行为；
* 应用程序验证
  * 检查自定义的错误处理代码；
  * 偏移量的提交方式；
  * 再均衡监听器及其他使用了Kafka客户端的地方；
* 生产环境的应用程序监控
  * 持续监控
可靠性不只是Kafka单方面的事情，应该从整个系统层面来考虑可靠性问题。

# 影响可靠性的配置？
* replication.factor: 复制系数；可作用于broker级别及Topic级别。
  * 建议为3。
* unclean.leader.election: 不完全的首领选举——允许不同步的跟随者副本成为首领。
  * unclean.leader.election.enable：设为true时启用。
* min.insync.replicas：最少同步副本。
  * 当同步副本少于要求的数量时，Kafka变为只读（不能生产只能消费）。

# 如何提高生产者的可靠性？
* 根据需求配吹恰当的acks值。
* 在参数配置和代码里正确处理Kafka返回的错误。（确保消息成功，不成功则重传等）
* 注意区分可重试错误，不可重试错误。

# 如何提高消费者的可靠性？
* 核心：跟踪哪些消息已消费，哪些没消费。（偏移量）
* 选择合适的偏移量提交时间及方式。
* 保证消费者行为可靠性的配置：
  * group.id
  * auto.offset.reset：指定没有偏移量可提交（消费者第一次启动）或请求的偏移量在broker不存在时，消费者会怎么做。
    * `earliest`：从分区开始位置读取数据。
    * `latest`：从分区末尾位置读取数据。
  * enable.auto.commit：让消费者基于`任务调度`自动提交偏移量。
  * auto.commit.interval.ms：自动提交的频率。默认5s/次。